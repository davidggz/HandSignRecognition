{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/david/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/david/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/david/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/david/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/david/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/david/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras as keras\n",
    "\n",
    "# Estos tienen solo una sola salida. 24x24\n",
    "df_letras_train = pd.read_csv(\"DatasetsIAO/Letras/sign_mnist_train.csv\")\n",
    "df_letras_test = pd.read_csv(\"DatasetsIAO/Letras/sign_mnist_test.csv\")\n",
    "\n",
    "# Estos están en one hot encoding. 64x64\n",
    "X_numeros = np.load(\"DatasetsIAO/NumerosBien/X.npy\")\n",
    "Y_numeros = np.load(\"DatasetsIAO/NumerosBien/Y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cambiar Y numeros a solo tener una salida **DONE**\n",
    "2. Juntar test y train de letras y separar en Y y X **DONE**\n",
    "3. Reescalar las imagenes de numeros de 64x64 a 28x28 **DONE**\n",
    "4. Juntar los datos de numeros y los de letras **DONE**\n",
    "5. Pasar todo el test a one hot encoding\n",
    "6. Separar en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_numeros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformamos a dataframe el np.array de Numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para manejar los dataset de los números, los pasamos a dataframe\n",
    "\n",
    "# Hacemos el reshape de X_numeros para que solo tenga dos dimensiones\n",
    "# y pueda ser representado en un dataframe.\n",
    "X_numeros = X_numeros.reshape(2062, 4096)\n",
    "\n",
    "# Pasamos tanto Y_numeros como X_numeros a dataframe.\n",
    "X_numeros = pd.DataFrame(data = X_numeros,\n",
    "          index=np.arange(1, X_numeros.shape[0] + 1),\n",
    "          columns=np.arange(1, X_numeros.shape[1] + 1))\n",
    "\n",
    "Y_numeros = pd.DataFrame(data = Y_numeros,\n",
    "          index=np.arange(1, Y_numeros.shape[0] + 1),\n",
    "          columns=np.arange(0, Y_numeros.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.521569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.607843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.639216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.521569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.286274</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.482353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.619608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.537255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.643137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2062 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7     \\\n",
       "1     0.474510  0.462745  0.450980  0.431373  0.419608  0.403922  0.392157   \n",
       "2     0.537255  0.517647  0.513726  0.501961  0.486274  0.482353  0.474510   \n",
       "3     0.435294  0.427451  0.415686  0.411765  0.396078  0.388235  0.376471   \n",
       "4     0.537255  0.647059  0.647059  0.470588  0.486274  0.486274  0.482353   \n",
       "5     0.305882  0.298039  0.294118  0.286274  0.278431  0.274510  0.266667   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2058  0.545098  0.537255  0.525490  0.517647  0.513726  0.501961  0.494118   \n",
       "2059  0.513726  0.498039  0.490196  0.478431  0.458824  0.450980  0.447059   \n",
       "2060  0.498039  0.486274  0.470588  0.454902  0.439216  0.427451  0.415686   \n",
       "2061  0.517647  0.498039  0.486274  0.478431  0.466667  0.450980  0.439216   \n",
       "2062  0.552941  0.541176  0.529412  0.517647  0.501961  0.494118  0.486274   \n",
       "\n",
       "          8         9         10    ...      4087      4088      4089  \\\n",
       "1     0.380392  0.372549  0.356863  ...  0.419608  0.431373  0.439216   \n",
       "2     0.470588  0.462745  0.454902  ...  0.509804  0.517647  0.529412   \n",
       "3     0.368627  0.364706  0.352941  ...  0.529412  0.541176  0.556863   \n",
       "4     0.478431  0.474510  0.462745  ...  0.392157  0.400000  0.407843   \n",
       "5     0.266667  0.258824  0.254902  ...  0.439216  0.450980  0.450980   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2058  0.478431  0.462745  0.447059  ...  0.564706  0.572549  0.580392   \n",
       "2059  0.443137  0.431373  0.419608  ...  0.427451  0.443137  0.458824   \n",
       "2060  0.400000  0.388235  0.376471  ...  0.537255  0.549020  0.556863   \n",
       "2061  0.427451  0.407843  0.392157  ...  0.454902  0.470588  0.478431   \n",
       "2062  0.474510  0.470588  0.462745  ...  0.549020  0.556863  0.572549   \n",
       "\n",
       "          4090      4091      4092      4093      4094      4095      4096  \n",
       "1     0.454902  0.466667  0.478431  0.486274  0.501961  0.509804  0.521569  \n",
       "2     0.541176  0.552941  0.564706  0.576471  0.588235  0.600000  0.607843  \n",
       "3     0.568627  0.580392  0.596078  0.611765  0.619608  0.631373  0.639216  \n",
       "4     0.423529  0.435294  0.450980  0.466667  0.486274  0.501961  0.521569  \n",
       "5     0.454902  0.458824  0.466667  0.466667  0.474510  0.478431  0.482353  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2058  0.588235  0.596078  0.603922  0.607843  0.615686  0.623529  0.627451  \n",
       "2059  0.470588  0.482353  0.494118  0.501961  0.513726  0.525490  0.529412  \n",
       "2060  0.564706  0.572549  0.576471  0.580392  0.588235  0.592157  0.619608  \n",
       "2061  0.486274  0.494118  0.501961  0.513726  0.517647  0.529412  0.537255  \n",
       "2062  0.584314  0.592157  0.603922  0.611765  0.623529  0.631373  0.643137  \n",
       "\n",
       "[2062 rows x 4096 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasamos de One Hot Encoding a Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2062 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "1     26\n",
       "2     26\n",
       "3     26\n",
       "4     26\n",
       "5     26\n",
       "...   ..\n",
       "2058  35\n",
       "2059  35\n",
       "2060  35\n",
       "2061  35\n",
       "2062  35\n",
       "\n",
       "[2062 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambiamos las salidas que están en one hot encoding\n",
    "# Sumamos 26 ya que luego va juntar los dos dataset. El número del 0 al 9 serán los números del 26 al 35\n",
    "Y_numeros['Clase'] = Y_numeros.apply(lambda row: np.argmax(row.values) + 26, axis = 1)\n",
    "\n",
    "# Eliminamos las columnas en one hot encoding\n",
    "Y_numeros = Y_numeros.drop([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], axis = 1)\n",
    "# Renombramos la clase para poder concatenarla posteriormente.\n",
    "Y_numeros = Y_numeros.rename(columns={'Clase': 0})\n",
    "Y_numeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación de train y test de letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34622</th>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>119</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>99</td>\n",
       "      <td>61</td>\n",
       "      <td>103</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>112</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>118</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>176</td>\n",
       "      <td>167</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34623</th>\n",
       "      <td>12</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>161</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>171</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>213</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34624</th>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>213</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34625</th>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>205</td>\n",
       "      <td>208</td>\n",
       "      <td>209</td>\n",
       "      <td>214</td>\n",
       "      <td>216</td>\n",
       "      <td>218</td>\n",
       "      <td>223</td>\n",
       "      <td>226</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>169</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>237</td>\n",
       "      <td>113</td>\n",
       "      <td>91</td>\n",
       "      <td>67</td>\n",
       "      <td>70</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34626</th>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>197</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>193</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34627 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          3     107     118     127     134     139     143     146     150   \n",
       "1          6     155     157     156     156     156     157     156     158   \n",
       "2          2     187     188     188     187     187     186     187     188   \n",
       "3          2     211     211     212     212     211     210     211     210   \n",
       "4         13     164     167     170     172     176     179     180     184   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "34622      1     135     119     108     102     105      99      61     103   \n",
       "34623     12     157     159     161     164     166     166     171     174   \n",
       "34624      2     190     191     190     191     190     190     192     192   \n",
       "34625      4     201     205     208     209     214     216     218     223   \n",
       "34626      2     173     174     173     174     173     173     175     175   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0         153  ...       207       207       207       207       206   \n",
       "1         158  ...        69       149       128        87        94   \n",
       "2         187  ...       202       201       200       199       198   \n",
       "3         210  ...       235       234       233       231       230   \n",
       "4         185  ...        92       105       105       108       133   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "34622     121  ...       108       112       116       114       118   \n",
       "34623     175  ...       213       213       213       214       213   \n",
       "34624     191  ...       216       215       213       214       214   \n",
       "34625     226  ...       112       169       255       255       237   \n",
       "34626     174  ...       201       200       197       198       198   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           206       206       204       203       202  \n",
       "1           163       175       103       135       149  \n",
       "2           199       198       195       194       195  \n",
       "3           226       225       222       229       163  \n",
       "4           163       157       163       164       179  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "34622       180       184       176       167       163  \n",
       "34623       211       210       210       209       208  \n",
       "34624       213       210       211       209       208  \n",
       "34625       113        91        67        70        63  \n",
       "34626       197       195       195       193       192  \n",
       "\n",
       "[34627 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenamos los dataframes de las letras (test y train)\n",
    "dataframes = [df_letras_train, df_letras_test]\n",
    "\n",
    "# Ponemos ignore_index para que se vuelva a hacer el index desde cero.\n",
    "dataset_letras = pd.concat(dataframes, ignore_index = True)\n",
    "dataset_letras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de letras en X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset de las letras en Y y X (labels y data)\n",
    "Y_letras = dataset_letras['label']\n",
    "#Y_letras = Y_letras.rename(columns={\"label\": \"Clase\"})\n",
    "X_letras = dataset_letras.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3\n",
       "1         6\n",
       "2         2\n",
       "3         2\n",
       "4        13\n",
       "         ..\n",
       "34622     1\n",
       "34623    12\n",
       "34624     2\n",
       "34625     4\n",
       "34626     2\n",
       "Name: label, Length: 34627, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_letras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize de las imagenes de Numeros a 24x24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenesNumeros = X_numeros.to_numpy().reshape(-1, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "newX = []\n",
    "# Hacemos reshape de todas las imagenes\n",
    "for img in imagenesNumeros:\n",
    "    newX.append(cv2.resize(img, dsize=(28, 28), interpolation = cv2.INTER_CUBIC))\n",
    "\n",
    "# Hacemos reshape de las imágenes de nuevo para poder hacer el dataframe\n",
    "X_numeros = np.asarray(newX).reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a transformar X_numeros en un dataframe para concatenarlo\n",
    "X_numeros = pd.DataFrame(data = X_numeros,\n",
    "          index=np.arange(1, X_numeros.shape[0] + 1),\n",
    "          columns=np.arange(1, X_numeros.shape[1] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.462483</td>\n",
       "      <td>0.427091</td>\n",
       "      <td>0.394643</td>\n",
       "      <td>0.367774</td>\n",
       "      <td>0.334802</td>\n",
       "      <td>0.309459</td>\n",
       "      <td>0.283324</td>\n",
       "      <td>0.266870</td>\n",
       "      <td>0.254762</td>\n",
       "      <td>0.243226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915330</td>\n",
       "      <td>0.910911</td>\n",
       "      <td>0.336705</td>\n",
       "      <td>0.365018</td>\n",
       "      <td>0.379212</td>\n",
       "      <td>0.404648</td>\n",
       "      <td>0.430508</td>\n",
       "      <td>0.459204</td>\n",
       "      <td>0.482923</td>\n",
       "      <td>0.512083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.521682</td>\n",
       "      <td>0.503947</td>\n",
       "      <td>0.479864</td>\n",
       "      <td>0.466226</td>\n",
       "      <td>0.445167</td>\n",
       "      <td>0.427047</td>\n",
       "      <td>0.414293</td>\n",
       "      <td>0.402481</td>\n",
       "      <td>0.396001</td>\n",
       "      <td>0.386312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385031</td>\n",
       "      <td>0.403118</td>\n",
       "      <td>0.424124</td>\n",
       "      <td>0.449125</td>\n",
       "      <td>0.471104</td>\n",
       "      <td>0.493565</td>\n",
       "      <td>0.517385</td>\n",
       "      <td>0.542870</td>\n",
       "      <td>0.573918</td>\n",
       "      <td>0.598595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.422101</td>\n",
       "      <td>0.404080</td>\n",
       "      <td>0.376979</td>\n",
       "      <td>0.359046</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.327971</td>\n",
       "      <td>0.313904</td>\n",
       "      <td>0.301414</td>\n",
       "      <td>0.294654</td>\n",
       "      <td>0.286108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361163</td>\n",
       "      <td>0.388719</td>\n",
       "      <td>0.411652</td>\n",
       "      <td>0.443075</td>\n",
       "      <td>0.483485</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.545177</td>\n",
       "      <td>0.570859</td>\n",
       "      <td>0.603719</td>\n",
       "      <td>0.630016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.606778</td>\n",
       "      <td>0.522206</td>\n",
       "      <td>0.520502</td>\n",
       "      <td>0.486466</td>\n",
       "      <td>0.443654</td>\n",
       "      <td>0.398807</td>\n",
       "      <td>0.360236</td>\n",
       "      <td>0.323207</td>\n",
       "      <td>0.291140</td>\n",
       "      <td>0.263414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355936</td>\n",
       "      <td>0.364150</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.370472</td>\n",
       "      <td>0.366925</td>\n",
       "      <td>0.380674</td>\n",
       "      <td>0.399303</td>\n",
       "      <td>0.424715</td>\n",
       "      <td>0.463264</td>\n",
       "      <td>0.510266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.301432</td>\n",
       "      <td>0.284540</td>\n",
       "      <td>0.267425</td>\n",
       "      <td>0.260785</td>\n",
       "      <td>0.251869</td>\n",
       "      <td>0.242710</td>\n",
       "      <td>0.238521</td>\n",
       "      <td>0.232798</td>\n",
       "      <td>0.227677</td>\n",
       "      <td>0.222605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485074</td>\n",
       "      <td>0.407750</td>\n",
       "      <td>0.416955</td>\n",
       "      <td>0.418422</td>\n",
       "      <td>0.424893</td>\n",
       "      <td>0.430363</td>\n",
       "      <td>0.445277</td>\n",
       "      <td>0.453620</td>\n",
       "      <td>0.462815</td>\n",
       "      <td>0.474009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>0.537683</td>\n",
       "      <td>0.524719</td>\n",
       "      <td>0.496842</td>\n",
       "      <td>0.464701</td>\n",
       "      <td>0.430125</td>\n",
       "      <td>0.397891</td>\n",
       "      <td>0.382709</td>\n",
       "      <td>0.367232</td>\n",
       "      <td>0.345250</td>\n",
       "      <td>0.326970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732651</td>\n",
       "      <td>0.787059</td>\n",
       "      <td>0.503986</td>\n",
       "      <td>0.513419</td>\n",
       "      <td>0.535482</td>\n",
       "      <td>0.552397</td>\n",
       "      <td>0.571577</td>\n",
       "      <td>0.586922</td>\n",
       "      <td>0.601254</td>\n",
       "      <td>0.621766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>0.501940</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>0.440233</td>\n",
       "      <td>0.431496</td>\n",
       "      <td>0.405710</td>\n",
       "      <td>0.375229</td>\n",
       "      <td>0.368060</td>\n",
       "      <td>0.357108</td>\n",
       "      <td>0.364894</td>\n",
       "      <td>0.340131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644599</td>\n",
       "      <td>0.638204</td>\n",
       "      <td>0.706651</td>\n",
       "      <td>0.650822</td>\n",
       "      <td>0.392736</td>\n",
       "      <td>0.411819</td>\n",
       "      <td>0.446470</td>\n",
       "      <td>0.472040</td>\n",
       "      <td>0.498636</td>\n",
       "      <td>0.521402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>0.484550</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.420070</td>\n",
       "      <td>0.389372</td>\n",
       "      <td>0.360940</td>\n",
       "      <td>0.335493</td>\n",
       "      <td>0.309546</td>\n",
       "      <td>0.295386</td>\n",
       "      <td>0.273797</td>\n",
       "      <td>0.258636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396650</td>\n",
       "      <td>0.432131</td>\n",
       "      <td>0.449556</td>\n",
       "      <td>0.466815</td>\n",
       "      <td>0.491682</td>\n",
       "      <td>0.517165</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.563221</td>\n",
       "      <td>0.575822</td>\n",
       "      <td>0.594861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>0.501560</td>\n",
       "      <td>0.470322</td>\n",
       "      <td>0.438682</td>\n",
       "      <td>0.409586</td>\n",
       "      <td>0.375214</td>\n",
       "      <td>0.349499</td>\n",
       "      <td>0.336483</td>\n",
       "      <td>0.314558</td>\n",
       "      <td>0.294482</td>\n",
       "      <td>0.280245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647045</td>\n",
       "      <td>0.679229</td>\n",
       "      <td>0.710384</td>\n",
       "      <td>0.733900</td>\n",
       "      <td>0.410592</td>\n",
       "      <td>0.435433</td>\n",
       "      <td>0.462818</td>\n",
       "      <td>0.482912</td>\n",
       "      <td>0.508557</td>\n",
       "      <td>0.523579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>0.545391</td>\n",
       "      <td>0.514690</td>\n",
       "      <td>0.485510</td>\n",
       "      <td>0.465712</td>\n",
       "      <td>0.445064</td>\n",
       "      <td>0.424709</td>\n",
       "      <td>0.405923</td>\n",
       "      <td>0.390262</td>\n",
       "      <td>0.378298</td>\n",
       "      <td>0.366350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623372</td>\n",
       "      <td>0.687854</td>\n",
       "      <td>0.794873</td>\n",
       "      <td>0.531841</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.534772</td>\n",
       "      <td>0.561612</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.603062</td>\n",
       "      <td>0.634372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2062 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4         5         6         7    \\\n",
       "1     0.462483  0.427091  0.394643  0.367774  0.334802  0.309459  0.283324   \n",
       "2     0.521682  0.503947  0.479864  0.466226  0.445167  0.427047  0.414293   \n",
       "3     0.422101  0.404080  0.376979  0.359046  0.343373  0.327971  0.313904   \n",
       "4     0.606778  0.522206  0.520502  0.486466  0.443654  0.398807  0.360236   \n",
       "5     0.301432  0.284540  0.267425  0.260785  0.251869  0.242710  0.238521   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2058  0.537683  0.524719  0.496842  0.464701  0.430125  0.397891  0.382709   \n",
       "2059  0.501940  0.476100  0.440233  0.431496  0.405710  0.375229  0.368060   \n",
       "2060  0.484550  0.449436  0.420070  0.389372  0.360940  0.335493  0.309546   \n",
       "2061  0.501560  0.470322  0.438682  0.409586  0.375214  0.349499  0.336483   \n",
       "2062  0.545391  0.514690  0.485510  0.465712  0.445064  0.424709  0.405923   \n",
       "\n",
       "           8         9         10   ...       775       776       777  \\\n",
       "1     0.266870  0.254762  0.243226  ...  0.915330  0.910911  0.336705   \n",
       "2     0.402481  0.396001  0.386312  ...  0.385031  0.403118  0.424124   \n",
       "3     0.301414  0.294654  0.286108  ...  0.361163  0.388719  0.411652   \n",
       "4     0.323207  0.291140  0.263414  ...  0.355936  0.364150  0.365741   \n",
       "5     0.232798  0.227677  0.222605  ...  0.485074  0.407750  0.416955   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2058  0.367232  0.345250  0.326970  ...  0.732651  0.787059  0.503986   \n",
       "2059  0.357108  0.364894  0.340131  ...  0.644599  0.638204  0.706651   \n",
       "2060  0.295386  0.273797  0.258636  ...  0.396650  0.432131  0.449556   \n",
       "2061  0.314558  0.294482  0.280245  ...  0.647045  0.679229  0.710384   \n",
       "2062  0.390262  0.378298  0.366350  ...  0.623372  0.687854  0.794873   \n",
       "\n",
       "           778       779       780       781       782       783       784  \n",
       "1     0.365018  0.379212  0.404648  0.430508  0.459204  0.482923  0.512083  \n",
       "2     0.449125  0.471104  0.493565  0.517385  0.542870  0.573918  0.598595  \n",
       "3     0.443075  0.483485  0.514085  0.545177  0.570859  0.603719  0.630016  \n",
       "4     0.370472  0.366925  0.380674  0.399303  0.424715  0.463264  0.510266  \n",
       "5     0.418422  0.424893  0.430363  0.445277  0.453620  0.462815  0.474009  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2058  0.513419  0.535482  0.552397  0.571577  0.586922  0.601254  0.621766  \n",
       "2059  0.650822  0.392736  0.411819  0.446470  0.472040  0.498636  0.521402  \n",
       "2060  0.466815  0.491682  0.517165  0.543993  0.563221  0.575822  0.594861  \n",
       "2061  0.733900  0.410592  0.435433  0.462818  0.482912  0.508557  0.523579  \n",
       "2062  0.531841  0.503333  0.534772  0.561612  0.582764  0.603062  0.634372  \n",
       "\n",
       "[2062 rows x 784 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos el dataframe de letras, ya que el dataframe de números \n",
    "# estaba normalizado y lo vamos a necesitar para entrenar a la red\n",
    "# de neuronas correctamente.\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = X_letras.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "# Debemos pasarle el nombre de las nuevas columnas ya que si no\n",
    "# no se concatenan correctamente.\n",
    "X_letras = pd.DataFrame(x_scaled, columns=list(range(1,785)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.792157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.584314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.886275</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.639216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.701961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34622</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.639216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34623</th>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.815686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34624</th>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.815686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34625</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.886275</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.247059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34626</th>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.752941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34627 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7    \\\n",
       "0      0.419608  0.462745  0.498039  0.525490  0.545098  0.560784  0.572549   \n",
       "1      0.607843  0.615686  0.611765  0.611765  0.611765  0.615686  0.611765   \n",
       "2      0.733333  0.737255  0.737255  0.733333  0.733333  0.729412  0.733333   \n",
       "3      0.827451  0.827451  0.831373  0.831373  0.827451  0.823529  0.827451   \n",
       "4      0.643137  0.654902  0.666667  0.674510  0.690196  0.701961  0.705882   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "34622  0.529412  0.466667  0.423529  0.400000  0.411765  0.388235  0.239216   \n",
       "34623  0.615686  0.623529  0.631373  0.643137  0.650980  0.650980  0.670588   \n",
       "34624  0.745098  0.749020  0.745098  0.749020  0.745098  0.745098  0.752941   \n",
       "34625  0.788235  0.803922  0.815686  0.819608  0.839216  0.847059  0.854902   \n",
       "34626  0.678431  0.682353  0.678431  0.682353  0.678431  0.678431  0.686275   \n",
       "\n",
       "            8         9         10   ...       775       776       777  \\\n",
       "0      0.588235  0.600000  0.611765  ...  0.811765  0.811765  0.811765   \n",
       "1      0.619608  0.619608  0.615686  ...  0.270588  0.584314  0.501961   \n",
       "2      0.737255  0.733333  0.729412  ...  0.792157  0.788235  0.784314   \n",
       "3      0.823529  0.823529  0.827451  ...  0.921569  0.917647  0.913725   \n",
       "4      0.721569  0.725490  0.729412  ...  0.360784  0.411765  0.411765   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "34622  0.403922  0.474510  0.521569  ...  0.423529  0.439216  0.454902   \n",
       "34623  0.682353  0.686275  0.690196  ...  0.835294  0.835294  0.835294   \n",
       "34624  0.752941  0.749020  0.752941  ...  0.847059  0.843137  0.835294   \n",
       "34625  0.874510  0.886275  0.898039  ...  0.439216  0.662745  1.000000   \n",
       "34626  0.686275  0.682353  0.686275  ...  0.788235  0.784314  0.772549   \n",
       "\n",
       "            778       779       780       781       782       783       784  \n",
       "0      0.811765  0.807843  0.807843  0.807843  0.800000  0.796078  0.792157  \n",
       "1      0.341176  0.368627  0.639216  0.686275  0.403922  0.529412  0.584314  \n",
       "2      0.780392  0.776471  0.780392  0.776471  0.764706  0.760784  0.764706  \n",
       "3      0.905882  0.901961  0.886275  0.882353  0.870588  0.898039  0.639216  \n",
       "4      0.423529  0.521569  0.639216  0.615686  0.639216  0.643137  0.701961  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "34622  0.447059  0.462745  0.705882  0.721569  0.690196  0.654902  0.639216  \n",
       "34623  0.839216  0.835294  0.827451  0.823529  0.823529  0.819608  0.815686  \n",
       "34624  0.839216  0.839216  0.835294  0.823529  0.827451  0.819608  0.815686  \n",
       "34625  1.000000  0.929412  0.443137  0.356863  0.262745  0.274510  0.247059  \n",
       "34626  0.776471  0.776471  0.772549  0.764706  0.764706  0.756863  0.752941  \n",
       "\n",
       "[34627 rows x 784 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34627, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb969cd4518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Hacemos reshape para que pasen de tener una sola dimensión, a tener 2 (de 784 a 28x28).\n",
    "# Esto es necesario para imprimir la imagen.\n",
    "prueba2 = X_letras.to_numpy().reshape(-1, 28, 28)\n",
    "print(prueba2.shape)\n",
    "plt.imshow(prueba2[1000], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2062, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb969c60e80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "prueba2 = X_numeros.to_numpy().reshape(-1, 28, 28)\n",
    "print(prueba2.shape)\n",
    "plt.imshow(prueba2[750], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntamos los dos dataset y randomizamos las instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36684</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36685</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36686</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36687</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36688</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36689 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clase\n",
       "0          3\n",
       "1          6\n",
       "2          2\n",
       "3          2\n",
       "4         13\n",
       "...      ...\n",
       "36684     35\n",
       "36685     35\n",
       "36686     35\n",
       "36687     35\n",
       "36688     35\n",
       "\n",
       "[36689 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_datasetTotal = [X_letras, X_numeros]\n",
    "Y_datasetTotal = [Y_letras, Y_numeros]\n",
    "\n",
    "X_datasetTotal = pd.concat(X_datasetTotal, ignore_index = True)\n",
    "Y_datasetTotal = pd.concat(Y_datasetTotal, ignore_index = True)\n",
    "Y_datasetTotal = Y_datasetTotal.rename(columns={0: 'Clase'})\n",
    "Y_datasetTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18836</th>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.886275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.623529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8554</th>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.850980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14536</th>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.878431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.772549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.301961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26028</th>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.827451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25390</th>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.949020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21754</th>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.917647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26242</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.850980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36689 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7    \\\n",
       "18836  0.803922  0.815686  0.823529  0.835294  0.850980  0.866667  0.874510   \n",
       "15998  0.349020  0.376471  0.396078  0.407843  0.423529  0.439216  0.443137   \n",
       "8554   0.815686  0.827451  0.827451  0.835294  0.839216  0.839216  0.843137   \n",
       "14536  0.494118  0.509804  0.525490  0.533333  0.549020  0.560784  0.572549   \n",
       "118    0.407843  0.431373  0.466667  0.494118  0.513725  0.529412  0.537255   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "25681  0.443137  0.462745  0.478431  0.490196  0.513725  0.541176  0.607843   \n",
       "26028  0.725490  0.729412  0.737255  0.741176  0.745098  0.749020  0.749020   \n",
       "25390  0.717647  0.737255  0.737255  0.745098  0.745098  0.749020  0.756863   \n",
       "21754  0.576471  0.596078  0.619608  0.635294  0.647059  0.658824  0.670588   \n",
       "26242  0.600000  0.619608  0.647059  0.666667  0.682353  0.698039  0.709804   \n",
       "\n",
       "            8         9         10   ...       775       776       777  \\\n",
       "18836  0.882353  0.882353  0.886275  ...  0.372549  0.356863  0.498039   \n",
       "15998  0.454902  0.462745  0.466667  ...  0.596078  0.600000  0.607843   \n",
       "8554   0.843137  0.847059  0.850980  ...  0.717647  0.725490  0.737255   \n",
       "14536  0.576471  0.588235  0.600000  ...  0.870588  0.874510  0.878431   \n",
       "118    0.556863  0.576471  0.584314  ...  0.341176  0.839216  0.796078   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25681  0.643137  0.670588  0.694118  ...  0.647059  0.356863  0.341176   \n",
       "26028  0.756863  0.756863  0.752941  ...  0.850980  0.850980  0.843137   \n",
       "25390  0.764706  0.768627  0.768627  ...  0.062745  0.000000  0.682353   \n",
       "21754  0.678431  0.690196  0.701961  ...  0.596078  0.564706  0.423529   \n",
       "26242  0.721569  0.733333  0.741176  ...  0.862745  0.870588  0.870588   \n",
       "\n",
       "            778       779       780       781       782       783       784  \n",
       "18836  0.470588  0.458824  0.462745  0.458824  0.462745  0.454902  0.439216  \n",
       "15998  0.607843  0.611765  0.607843  0.619608  0.623529  0.627451  0.623529  \n",
       "8554   0.737255  0.678431  0.509804  0.533333  0.584314  0.301961  0.211765  \n",
       "14536  0.882353  0.882353  0.882353  0.878431  0.882353  0.882353  0.878431  \n",
       "118    0.796078  0.792157  0.792157  0.788235  0.780392  0.776471  0.772549  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25681  0.250980  0.298039  0.313725  0.305882  0.317647  0.298039  0.301961  \n",
       "26028  0.843137  0.835294  0.835294  0.835294  0.831373  0.831373  0.827451  \n",
       "25390  1.000000  0.937255  0.945098  0.949020  0.949020  0.949020  0.949020  \n",
       "21754  0.815686  0.917647  0.901961  0.905882  0.909804  0.913725  0.917647  \n",
       "26242  0.874510  0.874510  0.866667  0.862745  0.862745  0.858824  0.850980  \n",
       "\n",
       "[36689 rows x 784 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cada vez que se ejecute esta celda, se obtendrá una aleatorización distinta de los datos.\n",
    "\n",
    "# Concatenamos las columnas para poder manejarlas mejor al hacer shuffle\n",
    "result = pd.concat([X_datasetTotal, Y_datasetTotal], axis = 1)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Aleatorizamos las imagenes\n",
    "result = shuffle(result)\n",
    "\n",
    "# Volvemos a generar los conjuntos X e Y\n",
    "X_datasetTotal = result.drop('Clase', axis = 1)\n",
    "Y_datasetTotal = result['Clase']\n",
    "\n",
    "X_datasetTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparamos las imágenes y las pasamos a One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el reshape para que las imagenes tengan el tamaño correcto\n",
    "X_datasetTotal = X_datasetTotal.values.reshape(X_datasetTotal.shape[0], 28, 28, 1)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "Y_datasetTotal = to_categorical(Y_datasetTotal.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36689, 36)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_datasetTotal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un total de 36 columnas por los siguientes motivos:\n",
    "\n",
    "- En total, el alfabeto tiene 26 letras. Hay dos que no podemos clasificar: la j y la z. La z no supone un problema ya que se encuentra al final, por lo que directamente no se tiene en cuenta. La j, al estar en el medio, el dataset se salta la etiqueta que debería tener. Esto hace que aun teniendo 24 etiquetas posibles, el array generado al hacer One Hot Encoding, llegue hasta la posición 25.\n",
    "\n",
    "\n",
    "- Al elegir las nuevas etiquetas de los números, le sumamos 26 debido a que la última etiqueta de las letras es la 25 (por los motivos recién mencionados). Esto hace que 26 + 10 = 36 que es el número de posibles valores que tenemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "nInstancias = math.ceil(0.7 * X_datasetTotal.shape[0])\n",
    "\n",
    "X_train = X_datasetTotal[:nInstancias]\n",
    "X_test = X_datasetTotal[nInstancias + 1:]\n",
    "\n",
    "Y_train = Y_datasetTotal[:nInstancias]\n",
    "Y_test = Y_datasetTotal[nInstancias + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25683, 36)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                18468     \n",
      "=================================================================\n",
      "Total params: 369,636\n",
      "Trainable params: 369,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Modelo de red neuronal\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(36, activation='softmax'))\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "test_generator = test_datagen.flow(X_test, Y_test, batch_size=32)\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=['categorical_crossentropy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "119/802 [===>..........................] - ETA: 20s - loss: 3.3830 - categorical_crossentropy: 3.3830"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-62e459e5a8ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=X_train.shape[0]//32,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=X_test.shape[0]//32\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelo-.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosas antiguas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el reshape para que las imagenes tengan el tamaño correcto\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "# Pasamos las salidas a one hot encoding. Aunque tenemos 24 clases\n",
    "# obtenemos un array de 25 posiciones. Esto se debe a que la J (numero\n",
    "# 9) también se tiene en cuenta, aunque no aparezca en ningún momento.\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# print(X_train.shape)\n",
    "# plt.imshow(X_train[0][:][:], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(path_npy + \"y_mnist_train.npy\", y)\n",
    "# np.save(path_npy + \"X_mnist_train.npy\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "# y = keras.utils.to_categorical(y)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Modelo de red neuronal\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(25, activation='softmax'))\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=32)\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=['categorical_crossentropy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='log/',\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=X_train.shape[0]//32,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=X_test.shape[0]//32,\n",
    "    callbacks=callbacks\n",
    "    )\n",
    "\n",
    "# model.save(\"modelo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
